{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from itertools import islice\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "from torchvision import transforms\n",
    "import v3io.dataplane\n",
    "\n",
    "class StreamDataLoader(IterableDataset):\n",
    "    def __init__(self, image_list, device, batch_size=32, img_dimensions=224):\n",
    "        \"\"\"\n",
    "        Stream Ingestion for DataLoader with batching. Also performs image pre-processing.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.image_list = image_list\n",
    "        self.batch_size = batch_size\n",
    "        self.img_dimensions = img_dimensions\n",
    "        self.transform = transforms.Compose([transforms.Resize((img_dimensions, img_dimensions)),\n",
    "                                            transforms.ToTensor()])\n",
    "        \n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Load image from path, perform pre-processing, and load onto device.\n",
    "        \"\"\"\n",
    "        image = Image.open(image_path)\n",
    "        return self.transform(image).to(self.device)\n",
    "    \n",
    "    def get_stream(self, image_list):\n",
    "        \"\"\"\n",
    "        Iterator that loads image from stream.\n",
    "        \"\"\"\n",
    "        for image in image_list:\n",
    "            yield self.load_image(image)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        PyTorch sub-classed method to invoke.\n",
    "        \"\"\"\n",
    "        return self.get_stream(self.image_list)\n",
    "    \n",
    "class ModelHandler:\n",
    "    def __init__(self, device, model_path='./dogs_vs_cats_resnet50.pth'):\n",
    "        \"\"\"\n",
    "        Handler for PyTorch model. Loads pre-trained model, performs predictions,\n",
    "        displays prediction labels, and displays original images with prediction label.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.labels = [\"cat\", \"dog\"]\n",
    "        self.model = self.load_model(model_path)\n",
    "    \n",
    "    def load_model(self, model_path, num_classes=2):\n",
    "        \"\"\"\n",
    "        Loads pre-trained model, sets to evaluation mode, and sends to device.\n",
    "        \"\"\"\n",
    "        model = torch.hub.load('pytorch/vision', 'resnet50')\n",
    "        model.fc = nn.Sequential(nn.Linear(model.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def batch_predict(self, batch):\n",
    "        \"\"\"\n",
    "        Gives prediction for batch of inputs.\n",
    "        \"\"\"\n",
    "        preds = self.model(batch)\n",
    "        return [pred.argmax() for pred in preds]\n",
    "        \n",
    "    def get_preds_labels(self, preds):\n",
    "        \"\"\"\n",
    "        Gives labels for batch of predictions\n",
    "        \"\"\"\n",
    "        return [self.labels[pred] for pred in preds]\n",
    "        \n",
    "    def display_preds(self, batch, preds, width, height):\n",
    "        \"\"\"\n",
    "        Displays original images with prediction labels in grid.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        for num, (sample, pred) in enumerate(zip(batch, preds)):\n",
    "            plt.subplot(height, width, num+1)\n",
    "            plt.title(self.labels[pred])\n",
    "            plt.axis('off')\n",
    "            sample = sample.to(self.device).numpy()\n",
    "            plt.imshow(np.transpose(sample, (1,2,0)))\n",
    "  \n",
    "def init_context(context):\n",
    "    \"\"\"\n",
    "    Init pre-trained model\n",
    "    \"\"\"\n",
    "    context.model_handler = ModelHandler(model_path=os.getenv(\"model_path\"), device=os.getenv(\"device\"))\n",
    "    context.v3io_client = v3io.dataplane.Client()\n",
    "\n",
    "def handler(context, event):\n",
    "    \"\"\"\n",
    "    Handler to perform real-time model inference using images\n",
    "    from stream. Can perform on GPU and CPU. Writes predictions to log.\n",
    "    \"\"\"\n",
    "        \n",
    "    image_list = json.loads(event.body)\n",
    "    \n",
    "    kwargs = {'num_workers': 0, 'pin_memory': False} if os.getenv(\"device\")=='cuda' else {}\n",
    "    context.stream_data_loader = StreamDataLoader(image_list=image_list, device=os.getenv(\"device\"))\n",
    "    context.loader = DataLoader(context.stream_data_loader, batch_size=int(os.getenv(\"batch_size\")), **kwargs)\n",
    "    \n",
    "    infer_start = time.time()\n",
    "    \n",
    "    # Iterate through batches from DataLoader, Query model and log predictions\n",
    "    batch_times = []\n",
    "    for i, batch in enumerate(islice(context.loader, int(os.getenv(\"num_batches\")))):\n",
    "        # Time prediction\n",
    "        batch_start = time.time()\n",
    "        preds = context.model_handler.batch_predict(batch=batch)\n",
    "        batch_end = time.time()\n",
    "        \n",
    "        # Calculate time taken\n",
    "        batch_time = batch_end - batch_start\n",
    "        batch_times.append(batch_time)\n",
    "        \n",
    "        # Log predicitons and batch inference time\n",
    "#         context.logger.info(context.model_handler.get_preds_labels(preds))\n",
    "        context.logger.info(f\"Batch {i+1} Inference Time: {batch_time}\")\n",
    "    \n",
    "    infer_end = time.time()\n",
    "    total_inference_time = infer_end - infer_start\n",
    "    avg_batch_inference_time = sum(batch_times) / int(os.getenv('num_batches'))\n",
    "    \n",
    "    context.logger.info(f\"Total Inference Time: {total_inference_time}\")\n",
    "    context.logger.info(f\"Avg Batch Inference Time: {avg_batch_inference_time}\")\n",
    "    \n",
    "    # Write metrics to KV\n",
    "    context.logger.info(\"Writing to KV\")\n",
    "    record = {str(infer_start) : {\"total_inference_time\" : str(total_inference_time),\n",
    "                                  \"avg_batch_inference_time\" : str(avg_batch_inference_time),\n",
    "                                  \"device\" : str(os.getenv(\"device\")),\n",
    "                                  \"batch_size\" : str(os.getenv(\"batch_size\")),\n",
    "                                  \"num_batches\" : str(len(batch_times))}}\n",
    "    for key, attributes in record.items():\n",
    "        context.v3io_client.kv.put(container=\"bigdata\",\n",
    "                                   table_path=os.getenv(\"table_path\"),\n",
    "                                   key=key,\n",
    "                                   attributes=attributes)\n",
    "    context.logger.info(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
