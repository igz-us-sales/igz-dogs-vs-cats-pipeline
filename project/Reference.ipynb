{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_model(num_classes=2):\n",
    "    model_resnet50 = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)\n",
    "    \n",
    "    for name, param in model_resnet50.named_parameters():\n",
    "        if \"bn\" not in name:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    model_resnet50.fc = nn.Sequential(nn.Linear(model_resnet50.fc.in_features,512),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout(),\n",
    "                                      nn.Linear(512, num_classes))\n",
    "    \n",
    "    return model_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch\", epoch)\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "            print(i, \"training_loss\", training_loss)\n",
    "            i +=1\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "                        \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "img_dimensions = 224\n",
    "\n",
    "# Normalize to the ImageNet mean and standard deviation\n",
    "# Could calculate it for the cats/dogs data set, but the ImageNet\n",
    "# values give acceptable results here.\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "img_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions,img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# data_path = \"/v3io/bigdata/dogs_vs_cats/data/train\"\n",
    "data_path = \"/v3io/bigdata/dogs_vs_cats_sample\"\n",
    "data = torchvision.datasets.ImageFolder(root=data_path,transform=img_transforms)\n",
    "# splits = [16000, 4500, 4500]\n",
    "# splits = [480, 240, 240, 24040]\n",
    "splits = [600, 200, 200]\n",
    "\n",
    "train_data, test_data, validation_data  = torch.utils.data.dataset.random_split(data, splits)\n",
    "\n",
    "num_workers = 6\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 480\n",
      "Num validation images: 240\n",
      "Num test images: 240\n"
     ]
    }
   ],
   "source": [
    "print(f'Num training images: {len(train_data_loader.dataset)}')\n",
    "print(f'Num validation images: {len(validation_data_loader.dataset)}')\n",
    "print(f'Num test images: {len(test_data_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    test_loss = 0.0\n",
    "    model.eval()\n",
    "    num_correct = 0 \n",
    "    num_examples = 0\n",
    "    with torch.no_grad():\n",
    "#         for data in test_data_loader:\n",
    "#             images, labels = data[0].to(device), data[1].to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        for batch in test_data_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            print(targets, predicted)\n",
    "            loss = nn.CrossEntropyLoss()(output,targets) \n",
    "            test_loss += loss.data.item() * inputs.size(0)\n",
    "                        \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        test_loss /= len(test_data_loader.dataset)        \n",
    "            \n",
    "        print('Test Loss: {:.4f}, Test Accuracy = {:.4f}'.format(test_loss, num_correct / num_examples))\n",
    "#     print('correct: {:d}  total: {:d}'.format(correct, total))\n",
    "#     print('accuracy = {:f}'.format(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prep_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-7eb6cf743b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_resnet50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prep_model' is not defined"
     ]
    }
   ],
   "source": [
    "model_resnet50 = prep_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0 training_loss 21.7574462890625\n",
      "1 training_loss 57.207489013671875\n",
      "2 training_loss 96.92254638671875\n",
      "3 training_loss 119.65019416809082\n",
      "4 training_loss 131.23123264312744\n",
      "5 training_loss 159.90755367279053\n",
      "6 training_loss 174.3070936203003\n",
      "7 training_loss 186.78234004974365\n",
      "8 training_loss 193.12980270385742\n",
      "9 training_loss 205.4397315979004\n",
      "10 training_loss 219.40852737426758\n",
      "11 training_loss 225.96051740646362\n",
      "12 training_loss 230.26807641983032\n",
      "13 training_loss 235.98478317260742\n",
      "14 training_loss 248.16403484344482\n",
      "Epoch: 0, Training Loss: 0.5170, Validation Loss: 0.1040, accuracy = 0.9708\n",
      "epoch 1\n",
      "0 training_loss 3.416419744491577\n",
      "1 training_loss 4.694213271141052\n",
      "2 training_loss 6.6063385009765625\n",
      "3 training_loss 9.436695337295532\n",
      "4 training_loss 11.923755645751953\n",
      "5 training_loss 12.503792345523834\n",
      "6 training_loss 14.764908850193024\n",
      "7 training_loss 15.50618052482605\n",
      "8 training_loss 16.729638814926147\n",
      "9 training_loss 17.086306750774384\n",
      "10 training_loss 17.46514990925789\n",
      "11 training_loss 27.65467169880867\n",
      "12 training_loss 29.588720828294754\n",
      "13 training_loss 29.9438653588295\n",
      "14 training_loss 31.432580888271332\n",
      "Epoch: 1, Training Loss: 0.0655, Validation Loss: 0.0264, accuracy = 0.9917\n"
     ]
    }
   ],
   "source": [
    "model_resnet50.to(device)\n",
    "optimizer = optim.Adam(model_resnet50.parameters(), lr=0.001)\n",
    "train(model_resnet50, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 0]) tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0]) tensor([1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0]) tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0]) tensor([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1]) tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 1])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0]) tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 0]) tensor([1, 0, 1, 0, 0, 1, 1, 0])\n",
      "Test Loss: 0.0536, Test Accuracy = 0.9850\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "def make_prediction(model, filename):\n",
    "    # 1 = dog, 0 = cat\n",
    "    labels = [\"cat\", \"dog\"]\n",
    "    img = Image.open(filename)\n",
    "    img = img_test_transforms(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    prediction = model(img.to(device))\n",
    "    prediction = prediction.argmax()\n",
    "    print(labels[prediction])\n",
    "\n",
    "make_prediction(model_resnet50, \"/v3io/bigdata/dogs_vs_cats/data/train/dog/dog.10440.jpg\")\n",
    "make_prediction(model_resnet50, \"/v3io/bigdata/dogs_vs_cats/data/train/cat/cat.12262.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/User/igz_repos/igz-dogs-vs-cats-pipeline/pipeline/18c05588-d087-4118-b469-dd8dd26cdccd/model.pkl\", \"rb\") as f:\n",
    "    model = loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_resnet50.state_dict(), \"./dogs_vs_cats_resnet50.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
